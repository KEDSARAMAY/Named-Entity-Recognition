{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thainer_Conditional_Random_Fields.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b7BGpYSBfPd",
        "colab_type": "text"
      },
      "source": [
        "# 1. Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jivk7RHLcfs5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "c6b433c1-3164-4eb8-cb21-b642e2da45f3"
      },
      "source": [
        "!pip install sklearn-crfsuite"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.8.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (4.41.1)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSvaj6dOOMFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "0a5d5bc6-ef75-49d2-832b-d3387271360a"
      },
      "source": [
        "!pip install pythainlp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pythainlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/30/5a9f31f4ff00a9918e4ac016d389ca8065a84ecd4b2d82a79315bdda9a4e/pythainlp-2.2.3-py3-none-any.whl (13.1MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1MB 1.4MB/s \n",
            "\u001b[?25hCollecting tinydb>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/f6/b3e112addc8eb4a097f158124ce8b206767361a381f80c5f0c506d855e4a/tinydb-4.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (2.23.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (0.9.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n",
            "Installing collected packages: tinydb, pythainlp\n",
            "Successfully installed pythainlp-2.2.3 tinydb-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e_icbLCTbQDV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "4dde8bdc-06d3-4a90-defd-83c4e2c213e3"
      },
      "source": [
        "!gdown --id 1uF2ycpXFCU-Li_FjjIWYXi5fOjl-tZlz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uF2ycpXFCU-Li_FjjIWYXi5fOjl-tZlz\n",
            "To: /content/fileforner.zip\n",
            "\r0.00B [00:00, ?B/s]\r4.60MB [00:00, 72.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S_oUt8oubR07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "359d8635-ba01-4847-dd5e-215e36be15a5"
      },
      "source": [
        "!unzip /content/fileforner.zip  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/fileforner.zip\n",
            "   creating: fileforner/\n",
            "  inflating: fileforner/evaluate.py  \n",
            "  inflating: fileforner/extract_answers.py  \n",
            "  inflating: fileforner/strip_answers.py  \n",
            "   creating: fileforner/thai_ner_dev_set/\n",
            "  inflating: fileforner/thai_ner_dev_set/corpus0150-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set/corpus0151-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set/corpus0152-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set/corpus0153-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set/corpus0154-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set/corpus0155-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set/corpus0156-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set/corpus0157-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set/corpus0158-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set/corpus0159-utf8.txt  \n",
            " extracting: fileforner/thai_ner_dev_set/Icon_  \n",
            "  inflating: fileforner/thai_ner_dev_set_answers.json  \n",
            "   creating: fileforner/thai_ner_dev_set_no_answers/\n",
            "  inflating: fileforner/thai_ner_dev_set_no_answers/corpus0150-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set_no_answers/corpus0151-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set_no_answers/corpus0152-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set_no_answers/corpus0153-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set_no_answers/corpus0154-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set_no_answers/corpus0155-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set_no_answers/corpus0156-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set_no_answers/corpus0157-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set_no_answers/corpus0158-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_dev_set_no_answers/corpus0159-utf8.txt  \n",
            "   creating: fileforner/thai_ner_train/\n",
            "  inflating: fileforner/thai_ner_train/corpus001-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0010-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0011-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0012-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0013-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0014-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0015-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0016-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0017-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0018-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0019-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus002-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0020-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0021-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0022-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0023-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0024-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0025-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0026-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0027-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0028-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0029-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus003-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0030-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0031-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0032-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0033-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0034-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0035-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0036-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0037-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0038-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0039-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus004-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0040-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0041-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0042-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0043-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0044-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0045-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0046-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0047-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0048-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0049-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus005-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0050-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0051-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0052-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0053-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0054-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0055-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0056-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0057-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0058-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0059-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus006-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0060-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0061-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0062-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0063-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0064-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0065-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0066-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0067-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0068-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0069-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus007-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0070-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0071-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0072-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0073-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0074-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0075-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0076-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0077-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0078-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0079-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus008-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0080-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0081-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0082-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0083-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0084-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0085-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0086-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0087-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0088-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0089-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus009-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0090-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0091-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0092-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0093-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0094-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0095-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0096-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0097-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0098-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0099-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0100-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0101-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0102-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0103-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0104-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0105-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0106-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0107-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0108-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0109-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0110-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0111-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0112-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0113-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0114-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0115-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0116-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0117-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0118-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0119-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0120-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0121-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0122-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0123-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0124-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0125-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0126-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0127-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0128-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0129-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0130-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0131-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0132-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0133-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0134-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0135-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0136-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0137-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0138-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0139-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0140-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0141-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0142-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0143-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0144-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0145-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0146-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0147-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0148-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train/corpus0149-utf8.txt  \n",
            " extracting: fileforner/thai_ner_train/Icon_  \n",
            "  inflating: fileforner/thai_ner_train_answers.json  \n",
            "   creating: fileforner/thai_ner_train_no_answers/\n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus001-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0010-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0011-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0012-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0013-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0014-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0015-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0016-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0017-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0018-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0019-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus002-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0020-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0021-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0022-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0023-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0024-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0025-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0026-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0027-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0028-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0029-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus003-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0030-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0031-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0032-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0033-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0034-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0035-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0036-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0037-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0038-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0039-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus004-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0040-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0041-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0042-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0043-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0044-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0045-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0046-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0047-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0048-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0049-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus005-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0050-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0051-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0052-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0053-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0054-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0055-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0056-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0057-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0058-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0059-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus006-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0060-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0061-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0062-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0063-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0064-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0065-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0066-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0067-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0068-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0069-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus007-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0070-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0071-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0072-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0073-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0074-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0075-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0076-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0077-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0078-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0079-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus008-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0080-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0081-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0082-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0083-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0084-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0085-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0086-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0087-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0088-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0089-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus009-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0090-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0091-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0092-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0093-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0094-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0095-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0096-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0097-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0098-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0099-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0100-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0101-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0102-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0103-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0104-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0105-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0106-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0107-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0108-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0109-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0110-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0111-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0112-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0113-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0114-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0115-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0116-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0117-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0118-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0119-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0120-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0121-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0122-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0123-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0124-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0125-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0126-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0127-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0128-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0129-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0130-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0131-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0132-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0133-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0134-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0135-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0136-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0137-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0138-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0139-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0140-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0141-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0142-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0143-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0144-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0145-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0146-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0147-utf8.txt  \n",
            "  inflating: fileforner/thai_ner_train_no_answers/corpus0148-utf8.txt  \n",
            " extracting: fileforner/thai_ner_train_no_answers/Icon_  \n",
            "   creating: fileforner/__MACOSX/\n",
            "  inflating: fileforner/__MACOSX/._thai_ner_dev_set  \n",
            "  inflating: fileforner/__MACOSX/._thai_ner_train  \n",
            "  inflating: fileforner/__MACOSX/._thai_ner_train_no_answers  \n",
            "   creating: fileforner/__MACOSX/thai_ner_dev_set/\n",
            "  inflating: fileforner/__MACOSX/thai_ner_dev_set/._corpus0150-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_dev_set/._corpus0151-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_dev_set/._corpus0152-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_dev_set/._corpus0153-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_dev_set/._corpus0154-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_dev_set/._corpus0155-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_dev_set/._corpus0156-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_dev_set/._corpus0157-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_dev_set/._corpus0158-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_dev_set/._corpus0159-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_dev_set/._Icon_  \n",
            "   creating: fileforner/__MACOSX/thai_ner_train/\n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus001-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0010-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0011-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0012-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0013-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0014-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0015-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0016-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0017-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0018-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0019-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus002-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0020-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0021-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0022-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0023-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0024-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0025-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0026-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0027-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0028-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0029-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus003-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0030-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0031-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0032-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0033-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0034-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0035-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0036-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0037-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0038-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0039-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus004-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0040-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0041-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0042-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0043-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0044-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0045-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0046-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0047-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0048-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0049-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus005-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0050-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0051-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0052-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0053-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0054-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0055-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0056-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0057-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0058-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0059-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus006-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0060-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0061-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0062-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0063-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0064-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0065-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0066-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0067-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0068-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0069-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus007-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0070-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0071-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0072-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0073-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0074-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0075-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0076-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0077-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0078-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0079-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus008-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0080-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0081-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0082-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0083-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0084-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0085-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0086-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0087-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0088-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0089-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus009-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0090-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0091-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0092-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0093-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0094-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0095-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0096-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0097-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0098-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0099-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0100-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0101-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0102-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0103-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0104-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0105-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0106-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0107-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0108-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0109-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0110-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0111-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0112-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0113-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0114-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0115-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0116-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0117-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0118-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0119-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0120-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0121-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0122-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0123-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0124-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0125-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0126-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0127-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0128-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0129-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0130-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0131-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0132-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0133-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0134-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0135-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0136-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0137-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0138-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0139-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0140-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0141-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0142-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0143-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0144-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0145-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0146-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0147-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0148-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._corpus0149-utf8.txt  \n",
            "  inflating: fileforner/__MACOSX/thai_ner_train/._Icon_  \n",
            "   creating: fileforner/__MACOSX/thai_ner_train_no_answers/\n",
            "  inflating: fileforner/__MACOSX/thai_ner_train_no_answers/._Icon_  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDqauDRtBfPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "e91b695e-48c9-45c6-9eac-b17aec397351"
      },
      "source": [
        "!head /content/fileforner/thai_ner_train/corpus001-utf8.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "สหพันธ์สตรีนักธุรกิจสากล เชิดชูเกียรตินักธุรกิจหญิงไทย [2 ธ.ค. 51 - 00:31]\n",
            " \n",
            "ถือเป็นต้นแบบของนักธุรกิจสตรีไทยคนแรกๆ ที่ทุ่มเทตัวเองให้กับอาชีพนักธุรกิจไปพร้อมๆกับทำงานการกุศลช่วยเหลือสังคมมาเป็นเวลายาวนาน จนได้รับรางวัลเชิดชูเกียรติมากมาย ล่าสุด < persName Id=\"001-p1\">จรรย์สมร วัธนเวคิน</ persName> นายหญิงแห่ง “เกียรตินาคิน” ยังได้รับรางวัล Badge of Honour Awards 2008 ซึ่งเป็นรางวัลเกียรติยศสูงสุดของ<orgName Id=\"001-org1\"><orgInd>สหพันธ์</orgInd>สมาคมสตรีนักธุรกิจและวิชาชีพสากล</orgName> (BPW International) ที่มอบให้แก่บุคคลผู้มีผลงานโดดเด่น และเป็นที่ยอมรับในระดับสากล นับเป็นคนไทยคนแรกที่ได้รับรางวัลนี้จากการประชุมใหญ่ ครั้งที่ 26 ของ BPW International ที่<placeName Id=\"001-place1\"><placeInd>ประเทศ</placeInd>เม็กซิโก </placeName>และงานเดียวกันนี้ <orgName Id=\"001-org1\"><abb>สธวท. </abb></orgName><placeName Id=\"001-place2\">กรุงเทพฯ</placeName> ยังคว้ารางวัลที่ 1 BPW Power to Make a Difference through Action หรือรางวัลโครงการพลังสร้างสรรค์การเปลี่ยนแปลงยอดเยี่ยม จากการจัดทำโครงการมอบโอกาสดีๆแก่สตรีอีกครั้ง ซึ่งเป็นโครงการฝึกทักษะอาชีพให้กับผู้ต้องขังหญิงในทัณฑสถานหญิง\n",
            "สำหรับรางวัล Badge of Honour Awards 2008 ที่ได้รับในครั้งนี้ < persName Id=\"001-p1\"><title>นาง</title>จรรย์สมร</ persName>กล่าวว่า นับเป็นรางวัลสูงสุดขององค์กรสากล นับจาก<orgName Id=\"001-org1\"><orgInd>สหพันธ์</orgInd>สมาคมสตรีนักธุรกิจและวิชาชีพสากล</orgName>ก่อตั้งมาเกือบ 80 ปี มีผู้ที่ได้รับรางวัลนี้เพียงไม่กี่คน จึงเป็นความภาคภูมิใจ และน่ายินดียิ่งที่ประเทศไทยเราได้รางวัลนี้ อย่างไร ก็ตาม ตัวเองเป็นเพียงตัวแทนของประเทศไทย ถ้าไม่มีทุกคนช่วยกันผลักดันผลงานเหล่านี้ให้สัมฤทธิผล ก็คงไม่มีโอกาสได้รางวัล ซึ่งรางวัลที่ได้รับนี้จะเป็นตัวอย่างให้คนรุ่นต่อไป มีความมุ่งมั่นตั้งใจที่จะทำอะไรเพื่อสังคมมากขึ้น\n",
            "\n",
            "< persName Id=\"001-p1\"><title>นาง</title>จรรย์สมร</ persName>กล่าวด้วยว่า ผู้หญิงไทยเรานั้นล้วนมีความเก่ง แต่อยู่ที่ว่าจะทำอย่างไรที่จะเปิดโอกาสให้เขาได้เข้ามามีส่วนร่วมช่วยเหลือสังคม และรู้จักดึงความเก่งที่มีอยู่ในแต่ละคนมารวมกัน ทำให้เป็นทีมเวิร์กเดียวกัน และเหตุที่ทำให้การทำงานในหลายเรื่องไม่ประสบความสำเร็จ เป็นเพราะเราไม่ยืนหยัด ไม่ต่อเนื่อง ไม่มีการส่งต่อ และติดตามผลงาน จึงต้องฝากความหวังไว้กับคนรุ่นใหม่ๆ \n",
            "\n",
            "พร้อมกันนี้ < persName Id=\"001-p1\"><title>นาง</title>จรรย์สมร</ persName>ยังได้กล่าวถึงการทำธุรกิจและทำงานเพื่อสังคมในเวลาเดียวกันว่า สมัยก่อนเรามักถือว่างานสังคมเป็นงานอาสาสมัคร ทำก็ได้ ไม่ทำก็ได้ แต่ปัจจุบันเราต้องทำงานสังคมให้เสมือนเป็นอาชีพที่เราอยากทำ จึงจะประสบความสำเร็จด้วยดี\n",
            "\n",
            "สำหรับผลงานสำคัญที่< persName Id=\"001-p1\"><title>นาง</title>จรรย์สมร</ persName>ได้ทำเพื่อสนับสนุนและส่งเสริมการพัฒนา และยกระดับสถานภาพสตรีที่ผ่านมา ครอบคลุมกลุ่มสตรีด้อยโอกาส สตรีในภาคธุรกิจ และสตรีในกลุ่มภาครัฐ อาทิ โครงการผลักดันให้สตรีมีสิทธิได้รับเลือกตั้งเป็นกำนัน-ผู้ใหญ่บ้าน เป็นผลสำเร็จ, การตั้งคลินิกธุรกิจ 26 สาขา, โครงการ “สตรีสามวัย-สามประสาน-สามพลังแห่งสหพันธ์” เชื่อมต่ออดีต ปัจจุบัน และอนาคตเข้าด้วยกัน โดยเชิญสตรีอาวุโสผู้มีประสบการณ์และความสุขุมมาร่วมประสาน เป็นคลังสมองให้กับสตรีวัยพัฒนา ซึ่งกำลังบริหารกิจการให้มีการพัฒนาอย่างยั่งยืน และสร้างสตรีวัยก้าวหน้า ซึ่งเป็นคนรุ่นใหม่ เข้ามาร่วมงานสืบทอด ปณิธานให้บรรลุเป้าหมาย เป็นต้น. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubNMKKjvtfua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "6818c0f5-455c-45ae-de93-3c618aa3f973"
      },
      "source": [
        "!ls  fileforner/thai_ner_train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus0010-utf8.txt  corpus0056-utf8.txt  corpus0101-utf8.txt\n",
            "corpus0011-utf8.txt  corpus0057-utf8.txt  corpus0102-utf8.txt\n",
            "corpus0012-utf8.txt  corpus0058-utf8.txt  corpus0103-utf8.txt\n",
            "corpus0013-utf8.txt  corpus0059-utf8.txt  corpus0104-utf8.txt\n",
            "corpus0014-utf8.txt  corpus005-utf8.txt   corpus0105-utf8.txt\n",
            "corpus0015-utf8.txt  corpus0060-utf8.txt  corpus0106-utf8.txt\n",
            "corpus0016-utf8.txt  corpus0061-utf8.txt  corpus0107-utf8.txt\n",
            "corpus0017-utf8.txt  corpus0062-utf8.txt  corpus0108-utf8.txt\n",
            "corpus0018-utf8.txt  corpus0063-utf8.txt  corpus0109-utf8.txt\n",
            "corpus0019-utf8.txt  corpus0064-utf8.txt  corpus0110-utf8.txt\n",
            "corpus001-utf8.txt   corpus0065-utf8.txt  corpus0111-utf8.txt\n",
            "corpus0020-utf8.txt  corpus0066-utf8.txt  corpus0112-utf8.txt\n",
            "corpus0021-utf8.txt  corpus0067-utf8.txt  corpus0113-utf8.txt\n",
            "corpus0022-utf8.txt  corpus0068-utf8.txt  corpus0114-utf8.txt\n",
            "corpus0023-utf8.txt  corpus0069-utf8.txt  corpus0115-utf8.txt\n",
            "corpus0024-utf8.txt  corpus006-utf8.txt   corpus0116-utf8.txt\n",
            "corpus0025-utf8.txt  corpus0070-utf8.txt  corpus0117-utf8.txt\n",
            "corpus0026-utf8.txt  corpus0071-utf8.txt  corpus0118-utf8.txt\n",
            "corpus0027-utf8.txt  corpus0072-utf8.txt  corpus0119-utf8.txt\n",
            "corpus0028-utf8.txt  corpus0073-utf8.txt  corpus0120-utf8.txt\n",
            "corpus0029-utf8.txt  corpus0074-utf8.txt  corpus0121-utf8.txt\n",
            "corpus002-utf8.txt   corpus0075-utf8.txt  corpus0122-utf8.txt\n",
            "corpus0030-utf8.txt  corpus0076-utf8.txt  corpus0123-utf8.txt\n",
            "corpus0031-utf8.txt  corpus0077-utf8.txt  corpus0124-utf8.txt\n",
            "corpus0032-utf8.txt  corpus0078-utf8.txt  corpus0125-utf8.txt\n",
            "corpus0033-utf8.txt  corpus0079-utf8.txt  corpus0126-utf8.txt\n",
            "corpus0034-utf8.txt  corpus007-utf8.txt   corpus0127-utf8.txt\n",
            "corpus0035-utf8.txt  corpus0080-utf8.txt  corpus0128-utf8.txt\n",
            "corpus0036-utf8.txt  corpus0081-utf8.txt  corpus0129-utf8.txt\n",
            "corpus0037-utf8.txt  corpus0082-utf8.txt  corpus0130-utf8.txt\n",
            "corpus0038-utf8.txt  corpus0083-utf8.txt  corpus0131-utf8.txt\n",
            "corpus0039-utf8.txt  corpus0084-utf8.txt  corpus0132-utf8.txt\n",
            "corpus003-utf8.txt   corpus0085-utf8.txt  corpus0133-utf8.txt\n",
            "corpus0040-utf8.txt  corpus0086-utf8.txt  corpus0134-utf8.txt\n",
            "corpus0041-utf8.txt  corpus0087-utf8.txt  corpus0135-utf8.txt\n",
            "corpus0042-utf8.txt  corpus0088-utf8.txt  corpus0136-utf8.txt\n",
            "corpus0043-utf8.txt  corpus0089-utf8.txt  corpus0137-utf8.txt\n",
            "corpus0044-utf8.txt  corpus008-utf8.txt   corpus0138-utf8.txt\n",
            "corpus0045-utf8.txt  corpus0090-utf8.txt  corpus0139-utf8.txt\n",
            "corpus0046-utf8.txt  corpus0091-utf8.txt  corpus0140-utf8.txt\n",
            "corpus0047-utf8.txt  corpus0092-utf8.txt  corpus0141-utf8.txt\n",
            "corpus0048-utf8.txt  corpus0093-utf8.txt  corpus0142-utf8.txt\n",
            "corpus0049-utf8.txt  corpus0094-utf8.txt  corpus0143-utf8.txt\n",
            "corpus004-utf8.txt   corpus0095-utf8.txt  corpus0144-utf8.txt\n",
            "corpus0050-utf8.txt  corpus0096-utf8.txt  corpus0145-utf8.txt\n",
            "corpus0051-utf8.txt  corpus0097-utf8.txt  corpus0146-utf8.txt\n",
            "corpus0052-utf8.txt  corpus0098-utf8.txt  corpus0147-utf8.txt\n",
            "corpus0053-utf8.txt  corpus0099-utf8.txt  corpus0148-utf8.txt\n",
            "corpus0054-utf8.txt  corpus009-utf8.txt   corpus0149-utf8.txt\n",
            "corpus0055-utf8.txt  corpus0100-utf8.txt  Icon_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKdk_9o0r9MR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "b6fdbdbf-5242-4c71-c546-e119cab8a218"
      },
      "source": [
        "!ls fileforner/thai_ner_dev_set_no_answers"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus0150-utf8.txt  corpus0154-utf8.txt  corpus0158-utf8.txt\n",
            "corpus0151-utf8.txt  corpus0155-utf8.txt  corpus0159-utf8.txt\n",
            "corpus0152-utf8.txt  corpus0156-utf8.txt\n",
            "corpus0153-utf8.txt  corpus0157-utf8.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ehOKxnCt-mU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71537d93-371c-4cc1-d28b-f0dc0b26b426"
      },
      "source": [
        " import glob\n",
        " train_filename = glob.glob('/content/fileforner/thai_ner_train/*.txt')\n",
        " print(len(train_filename))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awy0PtdhcIqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a11c6a8-f5f1-437c-871d-b16e3dfece88"
      },
      "source": [
        "train_filename"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/fileforner/thai_ner_train/corpus0016-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0014-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0090-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0065-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0137-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0131-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus003-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0070-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0107-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0147-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0024-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus002-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0051-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0060-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0132-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0075-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0066-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0057-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0101-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0049-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus005-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0138-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0134-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0067-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0058-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0050-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0019-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0102-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0064-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0088-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0145-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0015-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0038-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0135-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0081-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0030-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0091-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0097-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0096-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0108-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0017-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0115-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0121-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0120-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0031-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0119-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0130-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0089-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0110-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0084-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0117-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus008-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0012-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0027-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0111-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus004-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0118-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0039-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0122-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0054-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0035-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0105-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0069-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0028-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0068-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0129-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0034-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0099-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0026-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0036-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0142-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0020-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0025-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus007-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0048-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0029-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0037-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0022-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0053-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0085-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0041-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0086-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0114-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0112-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0045-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0106-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0141-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0013-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0146-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0018-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0124-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0059-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0095-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0044-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0033-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus001-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0077-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0046-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0087-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0148-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0098-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0093-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0074-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0133-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0023-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0149-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0113-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0136-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0080-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0103-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0055-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0109-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0139-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0127-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0123-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus009-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0071-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0052-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0128-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0082-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0140-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0073-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0094-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0083-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0072-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0062-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0126-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0056-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0010-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0143-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0104-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0092-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0063-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0144-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0032-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0042-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0078-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0011-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0047-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0040-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0076-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0043-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0116-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0021-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0125-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus006-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0100-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0079-utf8.txt',\n",
              " '/content/fileforner/thai_ner_train/corpus0061-utf8.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seUxN_i35TY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "349ad84a-440e-41f7-ad7c-eebbc37505f6"
      },
      "source": [
        " test_filename = glob.glob('/content/fileforner/thai_ner_dev_set_no_answers/*.txt')\n",
        " print(len(test_filename))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz4URxt2f4fT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "57715303-7ad7-472e-c3f4-8d28bacfe1e6"
      },
      "source": [
        "test_filename"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/fileforner/thai_ner_dev_set_no_answers/corpus0158-utf8.txt',\n",
              " '/content/fileforner/thai_ner_dev_set_no_answers/corpus0150-utf8.txt',\n",
              " '/content/fileforner/thai_ner_dev_set_no_answers/corpus0151-utf8.txt',\n",
              " '/content/fileforner/thai_ner_dev_set_no_answers/corpus0156-utf8.txt',\n",
              " '/content/fileforner/thai_ner_dev_set_no_answers/corpus0154-utf8.txt',\n",
              " '/content/fileforner/thai_ner_dev_set_no_answers/corpus0153-utf8.txt',\n",
              " '/content/fileforner/thai_ner_dev_set_no_answers/corpus0152-utf8.txt',\n",
              " '/content/fileforner/thai_ner_dev_set_no_answers/corpus0155-utf8.txt',\n",
              " '/content/fileforner/thai_ner_dev_set_no_answers/corpus0159-utf8.txt',\n",
              " '/content/fileforner/thai_ner_dev_set_no_answers/corpus0157-utf8.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxZ2MnhuodR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from pythainlp import word_tokenize\n",
        "from pythainlp.tokenize import syllable_tokenize\n",
        "from pythainlp.tag import pos_tag , pos_tag_sents\n",
        "import sklearn_crfsuite\n",
        "import sklearn_crfsuite.metrics\n",
        "import string\n",
        "import json"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkrIEUmQOkNe",
        "colab_type": "text"
      },
      "source": [
        "# **Extract file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_FHI7HjLkuIC",
        "colab": {}
      },
      "source": [
        "#train\n",
        "w_list_final_train = []\n",
        "tag_list_final_train = []\n",
        "for files in train_filename:\n",
        "  w_list = []\n",
        "  tag_list = []\n",
        "  with open(files) as f: \n",
        "    for line in re.split(r'\\n\\n+', f.read()):\n",
        "      line = line.strip()\n",
        "      data = re.split(r'<(pers|org|place)Name .+?>(.+?)</\\1Name>', line)\n",
        "      data = [re.sub(r'<.+?>', '', x) for x in data]\n",
        "      \n",
        "      index = 0\n",
        "      while index < len(data):\n",
        "        if data[index] in ['pers', 'org', 'place']:\n",
        "          type_ne = data[index]\n",
        "          w = syllable_tokenize(data[index+1])\n",
        "          w_list += w\n",
        "          tag_list += ['B-' + type_ne] + ['I-' + type_ne] * (len(w)-1)\n",
        "          index += 2\n",
        "        else:\n",
        "          w = syllable_tokenize(data[index])\n",
        "          w_list += w\n",
        "          tag_list += ['O'] * len(w)\n",
        "          index += 1\n",
        "    w_list_final_train.append(w_list)\n",
        "    tag_list_final_train.append(tag_list)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYB_IS9jwsF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b71ac806-b971-414c-f9a9-517a8931a80b"
      },
      "source": [
        "#test\n",
        "w_list_final_test = []\n",
        "for files in test_filename:\n",
        "  with open(files) as f:\n",
        "    w_list = []\n",
        "    data = []\n",
        "\n",
        "    for line in re.split(r'\\n\\n+', f.read()):\n",
        "      line = line.strip() \n",
        "      if \"(\" in line or \")\" in line:\n",
        "        line = line.replace( '(' , '$#@&($#@&').replace(')' , '$#@&)$#@&').split('$#@&')\n",
        "        data += line\n",
        "      else:\n",
        "        data += [line]\n",
        "    for index in range(len(data)):\n",
        "\n",
        "      w = syllable_tokenize(data[index])\n",
        "\n",
        "      w_list += w\n",
        "    w_list_final_test.append(w_list)\n",
        "\n",
        "len(w_list_final_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LabQ-lu1ivUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pos\n",
        "pos_train_w_list = pos_tag_sents(w_list_final_train)\n",
        "pos_test_w_list = pos_tag_sents(w_list_final_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0aocgHCXiNuR"
      },
      "source": [
        "# 2. Feature Engineering\n",
        "\n",
        "## Task 1: Implement orthographical features\n",
        "\n",
        "Feature function 3 ตัว ซึ่งเราออกแบบให้มี function header ที่เหมือนกันคือ `i, tokens` ตำแหน่ง token ที่ต้องการคำนวณ feature และ list ของ tuple (word, pos tag)\n",
        "\n",
        "*  ตัวอักษรแต่ละตัวเป็นตัวอักษรประเภทใด เช่น พยัญชนะ/สระ เครื่องหมายต่างๆ\n",
        "*  รูปร่างของตัวอักษรของทั้งคำเป็นแบบใด เช่น กกต. บริษัทxxx(จำกัด)\n",
        "\n",
        "`feature_dict`  should look like this\n",
        "`\n",
        "  {\n",
        "    'feature_name': 'feature_value',\n",
        "    'feature_name2': 'feature_value',\n",
        "  }\n",
        "  `"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzglcaPvtclr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "\n",
        "def is_digit(w_i,tokens):\n",
        "  return {'is_digit' : tokens[w_i][0].isdigit()}\n",
        "\n",
        "def word_shape1(token):\n",
        "\n",
        "  p = set(string.punctuation)\n",
        "  s = ''\n",
        "  for i in range(len(token)):\n",
        "    if token[i] in p:\n",
        "      s+= token[i]\n",
        "    elif token[i].isdigit():\n",
        "      s+= '1'\n",
        "    else:\n",
        "      s+=\"ก\"\n",
        "  return  s\n",
        "\n",
        "def word_shape2(w_i,tokens):\n",
        "  \n",
        "  current = word_shape1(tokens[w_i][0])\n",
        "  tnl = word_shape1(tokens[w_i-1][0]) if w_i > 0 else \"before_start\" #คำก่อนหน้า\n",
        "  tpl = word_shape1(tokens[w_i+1][0]) if w_i+1 <= len(tokens)-1 else \"end\" #คำถัดไป\n",
        "\n",
        "  return {'ws-0' : current , 'ws+1' : tpl  ,'ws-1': tnl}\n",
        "  \n",
        "def is_space1(token):\n",
        "  return token.isspace()\n",
        "\n",
        "def is_space2(w_i,tokens):\n",
        "  current = is_space1(tokens[w_i][0])\n",
        "  tnl = is_space1(tokens[w_i-1][0]) if w_i > 0 else \"before_start\" #คำก่อนหน้า\n",
        "  tpl = is_space1(tokens[w_i+1][0]) if w_i+1 <= len(tokens)-1 else \"end\" #คำถัดไป\n",
        "  return {'is_space-0' : current , 'is_space+1' : tpl  ,'is_space-1': tnl}\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FcJrivsrktwa"
      },
      "source": [
        "# 3. Train and evaluate models\n",
        "\n",
        "\n",
        "## Task 2: เขียน function สำหรับการ train และ evaluate\n",
        "\n",
        "* featurize training set และ dev set\n",
        "* fit CRF\n",
        "* Evaluate the results on the dev set\n",
        "* return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiXpzK1qBfP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def featurize_one_sentence(tokens, feature_function_list):\n",
        "    feature_dict_seq = []\n",
        "    for i in range(len(tokens)): # ทุก token\n",
        "        feature_dict = {}\n",
        "        for feature_fn in feature_function_list: # ทุก feature function\n",
        "            feature_dict.update(feature_fn(i, tokens))\n",
        "        feature_dict_seq.append(feature_dict)\n",
        "    return feature_dict_seq "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA0EpWZfGFhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from itertools import chain\n",
        "\n",
        "def bio_classification_report(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Classification report for a list of BIO-encoded sequences.\n",
        "    It computes token-level metrics and discards \"O\" labels.\n",
        "    \n",
        "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
        "    to calculate averages properly!\n",
        "    \"\"\"\n",
        "    lb = LabelBinarizer()\n",
        "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
        "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
        "        \n",
        "    tagset = set(lb.classes_) -{'O', 'pad', 'I-place'}\n",
        "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
        "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
        "    \n",
        "    return classification_report(\n",
        "        y_true_combined,\n",
        "        y_pred_combined,\n",
        "        labels = [class_indices[cls] for cls in tagset],\n",
        "        target_names = tagset\n",
        "    )"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW6_eKEBTc7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_evaluate(X_train, Y_train, X_test, feature_function_list):\n",
        "    training_data = [featurize_one_sentence( token_list,feature_function_list) for token_list in X_train]\n",
        "    crf = sklearn_crfsuite.CRF()\n",
        "    crf.fit(training_data,Y_train)\n",
        "    test_data = [featurize_one_sentence( token_list,feature_function_list) for token_list in X_test]\n",
        "    pred = crf.predict(test_data)\n",
        "    return pred"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iCPuLSfZif1-"
      },
      "source": [
        "# 4. More Feature Engineering and Experimenting\n",
        "## Task 3: Implement word type features\n",
        "\n",
        "Use spacy NLP preprocessor to obtain universal part of speech tags and write feature functions:\n",
        "\n",
        "`pos_features`\n",
        "* POS tag of the current word (t-0)\n",
        "* POS tag of the next word (t+1)\n",
        "* POS tag of the word after the next (t+2)\n",
        "* POS tag of the word after the next after the next (t+3)\n",
        "* POS tag of the previous word (t-1)\n",
        "* POS tag of the word before the previous (t-2)\n",
        "\n",
        "`pos_conjunctive_features`\n",
        "* POS tag of the t-2 AND t-1 AND t-0 AND t+1 AND t+2 AND t+3 (conjunctive features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2sznnbJvbfd3",
        "colab": {}
      },
      "source": [
        "def pos_features(i, tokens):\n",
        "   tnl2 = tokens[i-2][1] if i-1 > 0 else \"<?>\" #คำก่อนหน้า2\n",
        "   tnl = tokens[i-1][1] if i > 0 else \"<?>\" #คำก่อนหน้า\n",
        "   tpl = tokens[i+1][1] if i+1 <= len(tokens)-1 else \"</?>\" #คำถัดไป\n",
        "   tpl2 = tokens[i+2][1] if i+2 <= len(tokens)-1 else \"</?>\" #คำถัดไป2\n",
        "   tpl3 = tokens[i+3][1] if i+3 <= len(tokens)-1 else \"</?>\" #คำถัดไป2\n",
        "   return {'pos-0' : tokens[i][1], 'pos+1' : tpl  ,'pos-1': tnl,\"pos+2\" : tpl2,\"pos-2\" :tnl2}\n",
        "    \n",
        "def pos_conjunctive_features(i, tokens):\n",
        "   pos = pos_features(i,tokens)\n",
        "   return {'pos-conj' : pos['pos-2']+\"_\" + pos['pos-1']+\"_\" + pos['pos-0'] + \"_\"+pos['pos+1']+ \"_\"+pos['pos+2']}"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2czZ6dy7-mk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "1d8475a4-9ba7-47cc-c8ce-a0c7192e2cff"
      },
      "source": [
        "pos_features(2,pos_train_w_list[0])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pos+1': 'NCMN',\n",
              " 'pos+2': 'NCMN',\n",
              " 'pos-0': 'NCMN',\n",
              " 'pos-1': 'NCMN',\n",
              " 'pos-2': 'NCMN'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tSZQg2nIxOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77efb1b9-97ef-49af-9848-3f43d0ae6a05"
      },
      "source": [
        "pos_conjunctive_features(36,pos_test_w_list[-4])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pos-conj': 'NCMN_NCNM_PUNC_NCMN_PUNC'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hjhBjOvDi-VM"
      },
      "source": [
        "## Task 4: Word features\n",
        "This feature basically makes the model remember the name strings\n",
        "* current word (w-0)\n",
        "* next word (w+1)\n",
        "* the word after the next (w+2)\n",
        "* previous word (w-1)\n",
        "* the word before the previous (w-2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EUpGZPHwi-2-",
        "colab": {}
      },
      "source": [
        "def word_features(i, tokens):\n",
        "   tnl = tokens[i-1][0] if i > 0 else \"<?>\" #คำก่อนหน้า\n",
        "   tnl2 = tokens[i-2][0] if i-1 > 0 else \"<?>\" #คำก่อนหน้า\n",
        "\n",
        "   tpl = tokens[i+1][0] if i+1 <= len(tokens)-1 else \"</?>\" #คำถัดไ\n",
        "   tpl2 = tokens[i+2][0] if i+2 <= len(tokens)-1 else \"</?>\" #คำถัดไป\n",
        "   return {\"w-0\": tokens[i][0],\"w+1\":tpl,\"w-1\":tnl,\"w-2\" :tnl2 ,\"w+2\":tpl2}"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBmUHhlj1OqF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ede8d518-d841-49c1-9714-9740f5fbba78"
      },
      "source": [
        "word_features(12,pos_train_w_list[10])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'w+1': 'แจ้ง', 'w+2': 'เกิด', 'w-0': 'ได้', 'w-1': 'ไม่', 'w-2': 'จี'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cJlkdGiM-Yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm_pos_word_pred = train_and_evaluate(pos_train_w_list,tag_list_final_train, pos_test_w_list, \n",
        "                   [word_shape2,is_space2, pos_features,pos_conjunctive_features, word_features]) "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIv3AtA4Hfye",
        "colab_type": "text"
      },
      "source": [
        "# **Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYkRiCKjPcMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chunk_extract(all_w_list,all_tag_list, file_index):\n",
        "  \"\"\"\n",
        "  >>> chunk_extract([[เสาไห้ห่างไกลจากรุงเทพ....], []],[['O', 'B-PER', 'I-PER', 'B-ORG', 'O'], []], 1)\n",
        "  {place : [เสาไห้ , กรุงเทพ] , org : [เจริญโภค , คสช.] , pers : [ศดานันท์ , ศรันย์พร] }\n",
        "  \"\"\"\n",
        "  final_dict = {'place' : [] , 'org' : [] , 'pers' : []}\n",
        "  tag_list = all_tag_list[file_index]\n",
        "  w_list = all_w_list[file_index]\n",
        "  w_list = [w.replace('<space>', ' ') if w == '<space>' else w  for w in w_list]\n",
        "  w_list = [w.replace('<left_parenthesis>', '(') if w == '<left_parenthesis>' else w  for w in w_list]\n",
        "  w_list = [w.replace('<right_parenthesis>', ')') if w == '<right_parenthesis>' else w  for w in w_list]\n",
        "  \n",
        "  for i,tag in enumerate(tag_list):\n",
        "    if tag[0] == 'B':\n",
        "      word = ''\n",
        "      ner_type = tag[2:]\n",
        "      current = i + 1\n",
        "      if current == len(tag_list):\n",
        "        word = w_list[current-1]\n",
        "        if word not in final_dict[ner_type]:\n",
        "          #if \"(\" in word and \")\" not in word:\n",
        "           # word += \")\"\n",
        "\n",
        "          final_dict[ner_type].append(word)\n",
        "      else:\n",
        "        word = w_list[current-1]\n",
        "        while current < len(tag_list) and tag_list[current] == 'I-{}'.format(ner_type):\n",
        "          word += w_list[current]\n",
        "          current += 1\n",
        "        if word not in final_dict[ner_type]:\n",
        "          \n",
        "          final_dict[ner_type].append(word)\n",
        "  return final_dict"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wpnkaWj9ff_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cd71c7e-915c-4a16-cede-c931f940349e"
      },
      "source": [
        "len(norm_pos_word_pred)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkjcTyZ1rq-F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "bb6bd3a1-3ed3-42e7-9f1b-b86f7babbd43"
      },
      "source": [
        "chunk_extract(w_list_final_test,norm_pos_word_pred,1)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'org': ['บริษัท ตลาดอนุพันธ์ (ประเทศไทย',\n",
              "  'ทีเฟ็กซ์',\n",
              "  'ตลาดหลักทรัพย์แห่งประเทศไทย',\n",
              "  'ตลท.'],\n",
              " 'pers': ['นางเกศรา มัญชุศรี'],\n",
              " 'place': []}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvYcOpX9H0wM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_ans(all_w_list,all_tag_list,file_name_list):\n",
        "  name_dict = {name : {} for name in file_name_list}\n",
        "  for i in range(len(file_name_list)):\n",
        "    file_dict = chunk_extract(all_w_list,all_tag_list, i)\n",
        "    name_dict[file_name_list[i]].update(file_dict)\n",
        "  return name_dict"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9-oP9JaGkC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#key name file\n",
        "import os\n",
        "key_file = os.listdir('/content/fileforner/thai_ner_dev_set_no_answers/')\n",
        "key_file = [key for key in key_file if key.endswith(\".txt\")]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk6ZGkS_IENY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "9b407f91-fcab-4f12-d114-c3f9c0201649"
      },
      "source": [
        "key_file"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['corpus0158-utf8.txt',\n",
              " 'corpus0150-utf8.txt',\n",
              " 'corpus0151-utf8.txt',\n",
              " 'corpus0156-utf8.txt',\n",
              " 'corpus0154-utf8.txt',\n",
              " 'corpus0153-utf8.txt',\n",
              " 'corpus0152-utf8.txt',\n",
              " 'corpus0155-utf8.txt',\n",
              " 'corpus0159-utf8.txt',\n",
              " 'corpus0157-utf8.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGa-HA-o53yU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d5926464-fcf3-41a4-9a9f-4b1ac6e722a2"
      },
      "source": [
        "norm_ans1 = extract_ans(w_list_final_test,norm_pos_word_pred,key_file)\n",
        "norm_ans1"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'corpus0150-utf8.txt': {'org': ['บริษัท ตลาดอนุพันธ์ (ประเทศไทย',\n",
              "   'ทีเฟ็กซ์',\n",
              "   'ตลาดหลักทรัพย์แห่งประเทศไทย',\n",
              "   'ตลท.'],\n",
              "  'pers': ['นางเกศรา มัญชุศรี'],\n",
              "  'place': []},\n",
              " 'corpus0151-utf8.txt': {'org': ['คลัง',\n",
              "   'เอสเอ็มอีแบงก์',\n",
              "   'ธนาคารออมสิน',\n",
              "   'ธนาคารเพื่อการเกษตรและสหกรณ์การเกษตร',\n",
              "   'ธนาคารกรุงไทย',\n",
              "   'ศูนย์พยากรณ์เศรษฐกิจและธุรกิจ',\n",
              "   'มหาวิทยาลัยหอการค้าไทย'],\n",
              "  'pers': ['นายอภิสิทธิ์ เวชชาชีวะ',\n",
              "   'นายกรณ์ จาติกวณิช',\n",
              "   'นายกอร์ปศักดิ์ สภาวสุ',\n",
              "   'นายธนวรรธน์ พลวิชัย',\n",
              "   'นายอภิสิทธิ์',\n",
              "   'นางเสาวณีย์ ไทยรุ่งโรจน์'],\n",
              "  'place': ['ไทย', 'เวียดนามเอง']},\n",
              " 'corpus0152-utf8.txt': {'org': ['สำนักงานเศรษฐกิจการคลัง', 'สศค.', 'คลัง'],\n",
              "  'pers': ['นายสมชัย สัจจพงษ์', 'นายสมชัย', 'นายกรณ์ จาติกวณิช'],\n",
              "  'place': ['ไทย', 'สุวรรณภูมิ', 'ดอนเมือง']},\n",
              " 'corpus0153-utf8.txt': {'org': ['บริษัททรูมูฟ จำกัด',\n",
              "   'ศูนย์การค้าสยามพารากอน',\n",
              "   'ทรูมูฟ'],\n",
              "  'pers': ['นายศุภชัย เจียรวนนท์'],\n",
              "  'place': ['ไทย']},\n",
              " 'corpus0154-utf8.txt': {'org': ['สำนักงานคณะกรรมการพัฒนาการเศรษฐกิจและสังคมแห่งชาติ',\n",
              "   'สศช.',\n",
              "   'สำนักเลขาธิการนายกรัฐมนตรี',\n",
              "   'สำนักงานเศรษฐกิจการคลัง',\n",
              "   'สศค.',\n",
              "   'สำนักงบประมาณ',\n",
              "   'กรมบัญชีกลาง',\n",
              "   'สภาความมั่นคงแห่งชาติ',\n",
              "   'ธนาคารแห่งประเทศไทย',\n",
              "   'คณะกรรมการร่วมภาครัฐบาลและเอกชน',\n",
              "   'กรอ.',\n",
              "   'คลัง',\n",
              "   'กระทรวงการคลัง'],\n",
              "  'pers': ['นายอภิสิทธิ์ เวชชาชีวะ', 'นายกรณ์ จาติกวณิช'],\n",
              "  'place': ['ไทย', 'ท่าอากาศยานสุวรรณภูมิ']},\n",
              " 'corpus0155-utf8.txt': {'org': ['เทสโก้ โลตัส', 'มูลนิธิโครงการหลวง'],\n",
              "  'pers': ['นายสุนทร อรุณานนท์ชัย', 'นายสืบศักดิ์ นวจินดา'],\n",
              "  'place': ['เทสโก้',\n",
              "   'ญี่ปุ่น',\n",
              "   'เกาหลี',\n",
              "   'มาเลเซีย',\n",
              "   'จีน',\n",
              "   'ยุโรป',\n",
              "   'สหรัฐอเมริกา']},\n",
              " 'corpus0156-utf8.txt': {'org': ['กระทรวงการพัฒนาสังคมและความมั่นคงของมนุษย์',\n",
              "   'พม.'],\n",
              "  'pers': ['นายวัลลภ พลอยทับทิม'],\n",
              "  'place': []},\n",
              " 'corpus0157-utf8.txt': {'org': ['พรรคประชาธิปัตย์',\n",
              "   'หอการค้าไทย',\n",
              "   'สภาหอการค้าไทย',\n",
              "   'องค์การการค้าโลก',\n",
              "   'กระทรวงการคลัง',\n",
              "   'อังค์ถัด',\n",
              "   'โรงแรมอโนมา'],\n",
              "  'pers': ['นายเกียรติ สิทธีอมร',\n",
              "   'นายอภิสิทธิ์ เวชชาชีวะ',\n",
              "   'นายศุภชัย พานิชภักดิ์'],\n",
              "  'place': ['ไทย', 'กรุงเทพฯ', 'เอเชีย']},\n",
              " 'corpus0158-utf8.txt': {'org': ['กกอ.',\n",
              "   'สำนักงานคณะกรรมการการอุดมศึกษา',\n",
              "   'สกอ.',\n",
              "   'สกอ.มอบนโยบายกับมหาวิทยาลัย',\n",
              "   'กองทุนให้กู้ยืมเพื่อการศึกษา',\n",
              "   'กยศ.'],\n",
              "  'pers': ['ดร.สุเมธ แย้มนุ่น'],\n",
              "  'place': []},\n",
              " 'corpus0159-utf8.txt': {'org': ['มหาวิทยาลัยเกษตรศาสตร์',\n",
              "   'ม.เกษตรศาสตร์',\n",
              "   'อักษรศาสตร์',\n",
              "   'คณะประมง',\n",
              "   'องค์การศึกษาวิทยาศาสตร์และวัฒนธรรมแห่งสหประชาชาติ',\n",
              "   'เกษตรศาสตร์'],\n",
              "  'pers': ['รศ.วุฒิชัย กปิลกาญจน์',\n",
              "   'สมเด็จพระเจ้าลูกเธอ',\n",
              "   'สมเด็จ พระเจ้าลูกเธอ เจ้าฟ้าจุฬาภรณวลัยลักษณ์ อัครราช กุมารี',\n",
              "   'ม. เกษตรศาสตร์รศ.วุฒิชัย'],\n",
              "  'place': []}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRtLNo2yIgos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('my_answer_norm.json', 'w') as f:\n",
        "  json.dump(norm_ans1,f)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU21CvBXI8B3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "915723a9-cd99-4e19-d1eb-c7ea0d597e47"
      },
      "source": [
        "!python3 fileforner/evaluate.py fileforner/thai_ner_dev_set_answers.json my_answer_norm.json #word_shape,is_space,is_digit,is_place,is_org_or_abb,is_person_prf,is_place_prf,is_org_prf ,pos_features, pos_conjunctive_features, word_features"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'P': 0.9052631578947369, 'R': 0.8514851485148515, 'F1': 0.8775510204081632}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}